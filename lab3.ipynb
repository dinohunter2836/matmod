{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-surge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-april",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separate-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from heapq import heappush, heappop\n",
    "from numpy.random import exponential\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "posted-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventType(Enum):\n",
    "    Arrival = 1\n",
    "    Service = 2\n",
    "    Rejection = 3\n",
    "\n",
    "\n",
    "class Event:\n",
    "    def __init__(self, event_type: EventType, event_id: int, time: float, client: int) -> None:\n",
    "        self.type = event_type\n",
    "        self.channels_taken = 0\n",
    "        self.event_id = event_id\n",
    "        self.time = time\n",
    "        self.client = client\n",
    "\n",
    "    def __lt__(self, other) -> bool:\n",
    "        return self.time < other.time\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.event_id, self.time, self.client))\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'type={self.type} id={self.event_id} time={self.time} client={self.client}'\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "grateful-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialGenerator:\n",
    "    def __init__(self, param: float) -> None:\n",
    "        self.param = 1. / param\n",
    "\n",
    "    def __iter__(self) -> 'ExponentialGenerator':\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> float:\n",
    "        return exponential(self.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "opening-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventQueue:\n",
    "    def __init__(self) -> None:\n",
    "        self.events: tp.Set[Event] = set()\n",
    "        self.client_to_event: tp.Dict[int, Event] = {}\n",
    "        self.heap: tp.List[Event] = []\n",
    "\n",
    "    def push(self, event: Event) -> None:\n",
    "        heappush(self.heap, event)\n",
    "        self.client_to_event[event.client] = event\n",
    "        self.events.add(event)\n",
    "\n",
    "    def pop(self) -> tp.Optional[Event]:\n",
    "        while not self.empty():\n",
    "            event = heappop(self.heap)\n",
    "            if event in self.events:\n",
    "                self.events.remove(event)\n",
    "                self.client_to_event.pop(event.client)\n",
    "                return event\n",
    "\n",
    "    def remove(self, client: int) -> None:\n",
    "        self.events.remove(self.client_to_event[client])\n",
    "        self.client_to_event.pop(client)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.heap.clear()\n",
    "\n",
    "    def empty(self) -> bool:\n",
    "        return len(self.heap) == 0\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.heap)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.heap)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "japanese-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelCoopSimulator:\n",
    "    def __init__(\n",
    "            self,\n",
    "            channels: int,\n",
    "            arrival_rate: float,\n",
    "            max_request_channels: int,\n",
    "            service_function: tp.Callable[[int], float]\n",
    "    ) -> None:\n",
    "        self.channels = channels\n",
    "        assert arrival_rate > 0\n",
    "        self.arrival_rate = arrival_rate\n",
    "        self.arrival_generator = ExponentialGenerator(arrival_rate)\n",
    "        self.service_function = service_function\n",
    "        self.max_request_channels = max_request_channels\n",
    "        self.event_queue = EventQueue()\n",
    "        self.successes = 0\n",
    "        self.states = np.zeros(channels + 1, dtype='float64')\n",
    "\n",
    "    def __call__(self, max_time: float) -> None:\n",
    "        self.event_queue.clear()\n",
    "        self.event_queue.push(Event(EventType.Arrival, 0, next(self.arrival_generator), 0))\n",
    "        self.states.fill(0)\n",
    "        clients_count = 1\n",
    "        busy_channels = 0\n",
    "        events_count = 1\n",
    "        current_time = 0.\n",
    "        while current_time < max_time:\n",
    "            event = self.event_queue.pop()\n",
    "            state = busy_channels\n",
    "            self.states[state] += event.time - current_time\n",
    "            current_time = event.time\n",
    "            if event.type is EventType.Arrival:\n",
    "                if busy_channels < self.channels:\n",
    "                    current_channels = min(busy_channels + self.max_request_channels, self.channels) - busy_channels\n",
    "                    busy_channels += current_channels\n",
    "                    new_event = Event(\n",
    "                        EventType.Service,\n",
    "                        events_count,\n",
    "                        current_time + next(ExponentialGenerator(1 / self.service_function(current_channels))),\n",
    "                        event.client\n",
    "                    )\n",
    "                    new_event.channels_taken = current_channels\n",
    "                    self.event_queue.push(new_event)\n",
    "                    events_count += 1\n",
    "                    if busy_channels < self.channels:\n",
    "                        self.event_queue.push(Event(\n",
    "                            EventType.Arrival,\n",
    "                            events_count,\n",
    "                            current_time + next(self.arrival_generator),\n",
    "                            clients_count\n",
    "                        ))\n",
    "                        events_count += 1\n",
    "                        clients_count += 1\n",
    "                        \n",
    "                else:\n",
    "                    pass\n",
    "                    # raise ValueError('Something went wrong: trying to add customer with full queue')\n",
    "            elif event.type is EventType.Service:\n",
    "                self.event_queue.push(Event(\n",
    "                    EventType.Arrival,\n",
    "                    events_count,\n",
    "                    current_time + next(self.arrival_generator),\n",
    "                    clients_count\n",
    "                ))\n",
    "                events_count += 1\n",
    "                clients_count += 1\n",
    "                busy_channels -= event.channels_taken\n",
    "    \n",
    "    def evaluate(self) -> tp.Tuple[np.ndarray, int, int]:\n",
    "        if np.sum(self.states) == 0:\n",
    "            raise ValueError('Simulation has not been running or no events happened')\n",
    "        return self.states / np.sum(self.states)\n",
    "\n",
    "    def get_system_stats(self, probas: np.ndarray) -> tp.Dict[str, tp.Any]:\n",
    "        rejection_proba = probas[-1]\n",
    "        Q = 1 - rejection_proba\n",
    "        A = self.arrival_rate * Q\n",
    "        avg_busy_channels = self.channels * np.sum(probas[self.channels + 1:])\n",
    "        return [rejection_proba, A, avg_busy_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "future-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = ChannelCoopSimulator(5, 2., 2, lambda x: x)\n",
    "simulator(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "catholic-accountability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0073716 , 0.01302305, 0.07760525, 0.13836407, 0.21527971,\n",
       "       0.54835632])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = simulator.evaluate()\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "finite-america",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5483563183673222, 0.9032873632653555, 0.0]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator.get_system_stats(probas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
